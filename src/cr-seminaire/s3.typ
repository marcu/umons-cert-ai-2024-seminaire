= Séminaire 3

== L'intelligence artificielle et la société

Lors de la conférence intitulée "L'intelligence Artificielle et la société", Nathanaël Ackerman, directeur de l'IA au service public fédéral belge BOSA a présenté une vue d’ensemble des implications de l’intelligence artificielle sur la société, notamment dans le secteur public. Il a souligné que l'IA dépasse le cadre technologique traditionnel, la qualifiant, comme Andrew NG, de #emph[nouvelle électricité]. À l'instar de cette ressource, son impact est transversal et bouleverse les fondements de nombreux secteurs d’activité.

L’intervenant a rappelé que l'IA transforme aujourd’hui presque tous les aspects de la vie quotidienne, touchant l’éducation, les services publics, l’accès à l’information, et l’inclusion sociale. Cependant, cette évolution rapide requiert également une réflexion sur nos valeurs sociétales, notamment en matière de justice sociale et d’inclusion. Certaines dérives de l’IA, telles que les biais algorithmiques ou la concentration de pouvoir dans les grandes entreprises, mettent ces valeurs à l’épreuve et appellent à un réexamen des bases de notre société.

En tant que leader de la régulation mondiale dans le domaine technologique, l’Europe est bien consciente des enjeux socio-économiques liés à l’intelligence artificielle et a fait de cette technologie une priorité de la nouvelle Commission. Au-delà des aspects régulatoires, qui s’appuient sur la défense des droits fondamentaux et la construction d’un climat de confiance, l’Europe poursuit également un effet d’influence connu sous le nom de #emph[Brussels effect], où ses normes inspirent des pratiques globales. La stratégie européenne ne se limite pas à la régulation, mais prévoit aussi divers outils de soutien à la compétitivité pour aider les acteurs européens à rivaliser dans un marché globalisé. En tant que puissance régulatrice, l'Europe doit choisir ses combats et ses priorités avec soin pour maximiser ses ressources dans un secteur aussi compétitif et rapide que l’IA.

La Belgique, quant à elle, bénéficie d’une position privilégiée grâce à la proximité des institutions européennes et à l’accueil de l’AI Office, qui facilite l’entrée sur le marché de l’UE. Son écosystème dynamique, appuyé par des centres de recherche de pointe (JRC) et des programmes efficaces pour encourager l’adoption de l’IA au sein des entreprises, en fait un acteur central en Europe. Considérée comme un marché test idéal, la Belgique occupe une position centrale qui attire l’attention des innovateurs internationaux. Elle se classe d'ailleurs au 4ème rang dans EU Innovation Scoreboard, confirmant sa capacité d’innovation. De plus, les Régions belges jouent un rôle clé avec des plans solides et volontaristes, ainsi que des programmes de soutien aux entreprises pour renforcer leur compétitivité et accélérer l'adoption des technologies IA.

L’orateur a ensuite fait un retour sur l’évolution de l’IA, depuis ses débuts en 1956, jusqu'à l'accélération majeure des années 2010, marquée par des avancées comme la victoire d'AlphaGo en 2016 et la montée des modèles de langage (LLM), avec ChatGPT en 2022. Ces développements révèlent la complexité croissante des systèmes d'IA. Parmi les exemples mentionnés figurent AlexNet (2012), qui surpassait les humains en reconnaissance d’images, et Pluribus (2019), un programme qui a battu des professionnels du poker malgré leurs biais cognitifs.

L’une des préoccupations soulevées concernait les biais inhérents aux systèmes d’IA. À titre d’illustration, il a évoqué l’exemple d’Amazon, dont l'algorithme de sélection de CV favorisait les hommes en raison de données d’entraînement masculines prédominantes. Ce type de biais expose un défi fondamental : bien qu’un outil puissant, l’IA reflète souvent les inégalités ou préjugés intégrés aux données sur lesquelles elle se base.

Au-delà des biais, d’autres défis éthiques liés à l’IA ont également été abordés. Par exemple, dans le domaine de la justice, il a rappelé que des juges peuvent se montrer plus cléments après un repas, une réalité qui pourrait s'étendre aux systèmes de décision automatisés sans conception adéquate. La question de la responsabilité juridique en cas d'accidents impliquant des systèmes d’IA autonomes, tels que les véhicules sans conducteur, est également posée : qui en est responsable — le programmeur, le fabricant ou l’utilisateur ? (https://www.moralmachine.net/)

À l’ère de l’IA, la donnée est sans conteste l’une des ressources les plus précieuses. Comme l'a souligné The Economist en 2017, "#emph[la ressource la plus précieuse au monde n'est plus le pétrole, mais les données.]" Les géants technologiques comme Google et Microsoft l’ont bien compris, concentrant leurs efforts sur l’acquisition de données au travers par exemple de service gratuits offerts aux utilisateurs.

Le conférencier a également mis en avant le rôle crucial de la curation des données pour garantir la robustesse et éviter les biais des systèmes. Toutefois, il existe un dilemme majeur concernant la propriété intellectuelle et l'accès aux données d’entraînement. Comment rémunérer les créateurs de ces données ? Ce vide juridique reste un défi pour la régulation de l’IA.

Sur le plan professionnel, l’IA redessine également le marché du travail. L’orateur a averti des risques de #emph[fuite des cerveaux], où les talents européens cherchent des opportunités plus attractives à l’étranger, tout en soulignant que l’IA peut accroître la productivité et offrir de nouvelles perspectives pour les travailleurs qualifiés. Il devient essentiel d’intégrer l’IA dans les pratiques professionnelles pour rester pertinent dans un marché en évolution.

Par ailleurs, les soft skills, comme la créativité, la pensée critique, et la capacité de collaboration, seront indispensables pour évoluer dans un monde de plus en plus centré sur l’IA.

Le cadre réglementaire européen pour l'IA, en particulier l’AI Act adopté en 2024, vise à encadrer l’utilisation de ces systèmes dans l’Union européenne, imposant des exigences de transparence, de responsabilité et de robustesse. Ce texte s'inscrit dans un ensemble de régulations, dont le Digital Services Act et le Digital Markets Act, pour responsabiliser les plateformes en ligne et réguler les acteurs dominants du numérique.

Enfin, l'intervenant a évoqué la stratégie belge en matière d’IA, en mentionnant le plan national de convergence lancé en 2022. Ce plan poursuit des objectifs variés, comme la promotion d’une IA de confiance, l’amélioration de la cybersécurité, la compétitivité économique, ainsi que l’intégration de l’IA dans des secteurs clés tels que la santé et la mobilité.

En conclusion, il a insisté sur l'importance de développer une IA éthique, transparente et inclusive, respectueuse de la diversité et garante de bien-être sociétal et environnemental. Il a encouragé l’Europe à renforcer les briques essentielles de l’écosystème technologique pour rester compétitive face aux grandes puissances mondiales. Aujourd’hui, l’IA reflète notre société, et son développement doit s’aligner sur des valeurs humanistes et durables afin de maximiser les bénéfices et limiter les dérives pour tous.
