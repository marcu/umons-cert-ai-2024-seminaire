= Séminaire 3

== L'intelligence artificielle et la société

Nathanaël Ackerman, directeur de l’IA au service public fédéral belge BOSA, est venu nous exposer les implications de l'IA sur la société.

Premièrement, il faut se rendre compte que l'arrivée de l'IA est une révolution.

Andrew Ng, professeur expert à Stanford, a qualifié l'IA de "nouvelle électricité". Comme toute révolution, cela va introduire de grands changements dans la société. Comme pour les précédentes révolutions industrielles, on s'attend à ce que certains métiers disparaissent et ce, en très peu de temps. Mais contrairement aux précédentes révolutions, l'IA ne va pas toucher que les métiers peu qualifiés mais aussi les métiers qualifiés.

Un exemple : en Belgique, 15% des emplois sont dédiés au transport. Que va-t-il se passer pour ces emplois si les véhicules deviennent autonomes ?

La société, et donc le monde politique, doit donc s'intéresser à l'arrivée de l'IA. Même si le développement de l'IA est un travail qui a commencé bien longtemps, les pouvoirs publics ne s'y sont pas intéressés tout de suite. Il faut dire que l'IA a vécu deux périodes de doutes qu'on appelle "hivers de l'IA" (de 1974 à 1980, et de 1987 à 1993) où les financements ont été gelés.

Mais en 2016, l'IA a battu pour la première fois l'homme au jeu de GO (AlphaGo). À cette époque, l'administration Obama prend conscience de l'importance de réinvestir dans l'IA. Depuis, l'intérêt pour l'IA n'a cessé de croître, ainsi que les financements.

L'Europe a eu besoin d'un peu plus de temps pour entrer dans la course au développement de l'IA. Elle a pris du retard, surtout par rapport aux États-Unis, et il semble impossible que l'Europe rattrape son retard. Surtout que les pouvoirs publics européens ont une culture plus protectrice des citoyens par rapport aux innovations.

Le pari de l'Europe est de développer une IA digne de confiance, une IA éthique. Le processus a commencé en 2018 pour arriver à la proposition de l'IA Act en 2021. L'IA Act a seulement été adoptée en 2024 car mettre en place des normes prend du temps.

Un point crucial de l'IA Act a été de définir ce qu'est un système d’intelligence artificielle. La notion d'intelligence n'est pas simple à définir. L'Europe a choisi une définition de l'IA assez souple.

La définition qui a été retenue est la suivante : "Système automatisé conçu pour fonctionner à différents niveaux d'autonomie, qui peut faire preuve d'une capacité d'adaptation après son déploiement et qui, pour des objectifs explicites ou implicites, déduit, à partir des données d'entrée qu'il reçoit, la manière de générer des résultats tels que des prédictions, du contenu, des recommandations ou des décisions qui peuvent influencer les environnements physiques ou virtuels".

Dans l'IA Act, un point majeur est la définition du niveau de risque d'un système, qui va de :

- inacceptable (violation des fondamentaux tels que la dignité humaine, la démocratie ou l'État de droit)
- élevé (système dans des secteurs touchant à la santé, la gestion d'infrastructures critiques)
- IA à usage général (systèmes d'IA polyvalents comme ChatGPT)
- limité (IA permettant de générer ou manipuler des images, du son ou des vidéos)
- minimal (filtres anti-spam, jeux vidéo)

En fonction du niveau de risque, chaque déployeur/fournisseur a des contraintes à respecter.

Avec l'IA Act, le citoyen européen sera normalement protégé de l'IA. Il faut s'assurer que l'IA ne comporte pas de biais qui puissent nuire à une partie de la population.

En effet, il existe pas mal d'exemples où l'IA reproduit des biais existants dans la société (femmes proposées à des postes avec moins de responsabilités, discrimination de personnes de couleur pour les aides sociales). L'idée de l'IA Act est de proposer un cadre légal pour éviter ce genre de cas.

J'ai beaucoup aimé l'intervention de Nathanaël Ackerman car il nous a fait prendre conscience de l'impact que l'IA va avoir sur la société. Sur le fait que la société, au travers du pouvoir politique, doit encadrer l'utilisation de l'IA dans la société. Je trouve que la position que l'Europe a adoptée est intéressante. Trouver le juste équilibre entre l'innovation à tout prix ou la protection des citoyens n'est pas facile. Je pense qu'il faudra sûrement adapter cette position, mais c'est rassurant de voir qu'il y a déjà une réflexion qui a été engagée, même si on peut trouver que la réponse politique est assez lente.

Aussi, cet exposé m'a fait prendre conscience de l'importance du choix des IA que nous utilisons. En tant que consommateur, notre choix a un impact et il me semble qu'il est important de privilégier l'IA européenne parce qu'elle me semble plus éthique. De plus, si on regarde le développement du monde informatique, on voit qu'on arrive souvent à des monopoles (après une période où la concurrence est écrasée grâce à des investissements massifs). J'ai l'impression qu'on va arriver à une situation similaire pour l'IA. Cela m'incite à soutenir l'IA européenne pour qu'elle puisse se développer et proposer des alternatives aux IA américaines.