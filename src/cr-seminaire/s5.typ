= Séminaire 5

== L'intelligence artificielle et l'éthique

Ce séminaire a été présenté par Valerie Zapico, fondatrice de la société Valkuren, et a abordé le sujet du biais dans l'IA.

Un biais est une distorsion (déviation systématique par rapport à une norme) que subit une information en entrant dans des systèmes ou en sortant. Dans le premier cas, le sujet opère une sélection des informations ; dans le second, il réalise une sélection des réponses.

Comme nous avons déjà vu dans d'autres séminaires, l'IA peut comporter beaucoup de biais.

Premièrement, il est important de souligner que l'IA n'est pas un outil parfait. Il a été démontré que le fait que l'IA soit principalement développée par des hommes blancs a une influence sur les IA qui sont développées.

Un exemple : un algorithme d'identification du genre à partir d'une photo d'un homme blanc avait un taux d'erreur de 1 %, alors que si la photo affiche une femme noire, le taux d'erreur est de 35 %.

Un second exemple est la reconnaissance vocale qui, à un certain moment, a eu du mal à comprendre les voix de femmes.

Le biais peut, aussi, être plus insidieux en reproduisant des a priori. Un exemple : retraduire vers le français le résultat de la traduction vers le turc de "Il est infirmier. Elle est docteur." donne au final "C'est une infirmière. C'est un docteur".

Cela peut être considéré comme cocasse et vu comme une maladie de jeunesse.

Mais c'est très problématique car l'IA peut être utilisée dans des domaines ayant un fort impact sur la vie des gens. Par exemple, une IA a été développée pour évaluer à partir d'une photo le risque qu'une personne commette un délit. Cette IA a évalué ce risque à 3 pour un homme blanc avec tatouages et cicatrices et à 8 pour une femme noire sans caractéristiques particulières.

On peut imaginer que ces problèmes sont involontaires et générés par le manque de diversité des équipes de développement. De ce fait, lors des entraînements et des tests d'une IA, certains cas sont moins travaillés ou explorés. Les ingénieurs ont testé avec des données issues de leur monde. Ils ont imaginé que si ça fonctionnerait pour des hommes blancs, ça fonctionnerait aussi pour les autres catégories de la population.

De plus, l'IA ne fait que reproduire le jugement humain et la société humaine qui sont pleins de biais.

Les sources de biais sont multiples :

- biais techniques
    - base de données de mauvaise qualité,
    - données non représentatives de la réalité
    - manque de représentativité de certains sous-groupes
- biais de société
    - biais cognitifs (notre vision du monde influence la manière dont nous traitons l'information)
    - biais émotionnels (nos émotions distordent nos jugements).

Madame Zapico a donc insisté sur le fait qu'il faille faire attention lors de la conception d'une IA à ne pas y intégrer des biais.

On parle alors d'équité algorithmique qui correspond à l’absence de tout favoritisme ou discrimination à l’égard d’un individu ou d’un groupe formé par des caractéristiques innées ou acquises. C'est un concept qui n'est pas facile à définir et qui peut varier selon les cultures, qui n'a pas de définition unique (cela varie selon les cultures).

Lors de la création d'une IA, il faut donc vérifier et évaluer l’absence de tout tort, discrimination que pourraient engendrer les décisions prises par un algorithme.

Une manière de faire est de définir précisément les biais à éviter afin de mettre en place des métriques permettant de mesurer ces biais et de pouvoir corriger l'IA.

Il faut aussi faire très attention aux données utilisées pour entraîner l'IA et aussi vérifier que les données utilisées soient bien représentatives de la réalité. Le nettoyage de la donnée est donc une étape très importante.

J'ai beaucoup apprécié l'intervention de Valerie Zapico qui a mis en évidence le sujet du biais. C'est un sujet qui est très important dans l'IA et auquel il faut faire très attention afin que l'IA soit un réel progrès. Les gens qui développent l'IA doivent être conscients que si une IA est biaisée, elle ne sera pas acceptée par la société.