= Séminaire 5

== L'intelligence artificielle et l'éthique

Ce séminaire a été présenté par Valerie Zapico.

Madame Zapico, dans un premier temps, définit ce qu'est un biais.

Un biais est une distorsion (déviation systématique par rapport à une norme) que subit une information en entrant dans des systèmes ou en sortant. Dans le premier cas, le sujet opère une sélection des informations ; dans le second, il réalise une sélection des réponses.

Comme nous avons déjà vu dans d'autres séminaires, l'IA peut comporter beaucoup de biais.

Premièrement, il est important de souligner que l'IA n'est pas un outil parfait. Principalement, les ingénieurs qui créent les IA sont des hommes blancs. Cela a une grande importance : lors de l'entraînement d'une IA, certains cas sont moins travaillés ou explorés.

Un exemple : un algorithme d'identification du genre à partir d'une photo d'un homme blanc avait un taux d'erreur de 1 %, alors que si la photo affiche une femme noire, le taux d'erreur est de 35 %.

Un second exemple est la reconnaissance vocale qui a du mal à comprendre les voix de femmes.

On peut comprendre que les ingénieurs ont testé avec des données issues de leur monde et n'ont imaginé que cela fonctionnerait que pour des hommes blancs, cela fonctionnerait aussi pour les autres catégories de la population.

Le biais peut être aussi plus insidieux et reproduire des a priori. Un exemple : retraduire vers le français le résultat de la traduction vers le turc de "Il est infirmier. Elle est docteur." donne au final "C'est une infirmière. C'est un docteur".

Cela peut être cocasse et vu comme une maladie de jeunesse, mais ça peut devenir très problématique, par exemple pour une IA qui associe à une photo le risque que cette personne fasse un délit : pour un homme blanc avec tatouages et cicatrices, ce risque est évalué à 3, alors que pour une femme noire sans caractéristiques particulières, ce risque est évalué à 8.

Le fait que l'IA comporte des biais peut se comprendre car le jugement humain est aussi très biaisé.

Les sources de biais sont multiples :

- biais techniques
    - base de données de mauvaise qualité,
    - données non représentatives de la réalité
    - manque de représentativité de certains sous-groupes
- biais de société
    - biais cognitifs (notre vision du monde influence la manière dont nous traitons l'information)
    - biais émotionnels (nos émotions distordent nos jugements)

Il faut faire très attention afin d'éviter au maximum les biais.

Idéalement, il faut favoriser l'équité. C'est un concept qui n'est pas facile à définir et qui n'a pas de définition unique (cela varie selon les cultures).

Dans le cadre algorithmique, on dira : L’équité algorithmique correspond à l’absence de tout favoritisme ou discrimination à l’égard d’un individu ou d’un groupe formé par des caractéristiques innées ou acquises.

Il s’agit donc de vérifier et d’évaluer l’absence de tout tort, discrimination que pourraient engendrer les décisions prises par un algorithme.

L’enjeu consiste alors à définir précisément ces biais que l’on souhaite éviter afin de mettre en place des métriques permettant de les mesurer et les corriger.

Il faut nettoyer les données, faire des choix.

J'ai beaucoup apprécié l'intervention de Valerie Zapico qui a mis en évidence le sujet du biais. C'est un sujet qui est très important dans l'IA et auquel il faut faire très attention afin que l'IA soit un réel progrès.


