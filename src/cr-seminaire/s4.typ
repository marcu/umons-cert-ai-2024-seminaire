= Séminaire 4

== L'intelligence artificielle et le droit

Le séminaire "L'intelligence artificielle et le droit", présenté par Charles
Bernard du cabinet Janson, a mis en lumière les nombreuses intersections entre
les avancées en intelligence artificielle et les questions juridiques qui les
accompagnent. Au cours de cette conférence, plusieurs défis ont été discutés,
touchant à la fois à la responsabilité civile, à la protection des données, et
aux implications éthiques et légales de l’utilisation de l’IA dans divers
domaines. Ces problématiques soulignent l’urgence pour le droit de s’adapter
face à des systèmes autonomes dont l’évolution rapide complexifie la
législation.

L’intervention a débuté par une analyse des préoccupations juridiques de base,
notamment la question de la "représentabilité" en matière d'IA, c’est-à-dire la
capacité de la loi à représenter et réguler des entités non humaines. Charles
Bernard a rappelé la résolution du Parlement européen du 16 février 2017, qui
s'efforce de poser un cadre pour la robotique civile. Dans cette optique, il a
exploré la question d'une potentielle législation autour des lois d’Asimov,
soulevant des interrogations profondes sur l’éthique et la faisabilité de telles
règles dans notre société contemporaine.

Des exemples concrets ont été utilisés pour illustrer les défis juridiques de
l'IA, en commençant par la justice prédictive et la police prédictive, des
domaines autrefois limités à la science-fiction mais devenus réalité avec des
systèmes comme le Crime Anticipation System. Toutefois, ces systèmes sont loin
d’être neutres. L’intervenant a souligné que des études montrent des biais dans
ces technologies, tels que le biais racial détecté dans l’algorithme COMPAS, un
système de justice prédictive utilisé pour évaluer les risques de récidive. Un
autre cas marquant est le chatbot Tay de Microsoft, qui a développé des propos
antisémites et racistes en quelques heures après son lancement, démontrant à
quel point l’IA peut être influencée par les biais présents dans les données
d’apprentissage.

L’application de l’IA dans l’administration publique a également été abordée,
comme en témoigne l'exemple du scandale des allocations familiales aux Pays-Bas
en 2021. L’IA utilisée pour détecter la fraude a conduit à des erreurs et des
discriminations, illustrant l'importance de la transparence et de la précision
dans ces technologies. La reconnaissance faciale, avec des exemples controversés
comme Clearview AI, pose aussi des questions fondamentales sur le respect de la
vie privée et la légalité des pratiques de collecte de données.

Dans le cadre de l'AI Act, la nouvelle réglementation européenne
(règlement 2024/1689), l'Union européenne a mis en place un cadre légal qui vise
à réguler l'utilisation de l'IA en Europe en imposant des exigences de
transparence, de robustesse et de responsabilité. Ce règlement, qui entrera en
vigueur en 2026, s’applique à la fois aux fournisseurs et aux utilisateurs de
systèmes d'IA, y compris les entreprises non européennes. Les systèmes d’IA sont
désormais classés en plusieurs catégories de risques : des risques
"inacceptables" (comme Clearview AI) aux risques "élevés" (touchant à la
migration, la formation, la justice, etc.), nécessitant des exigences strictes
de gestion des risques, de contrôle humain, et de transparence. Des dispositions
sont également prévues pour encourager l'innovation, comme la création de
"sandbox réglementaires" permettant des expérimentations dans des conditions
contrôlées.

Une section importante de la conférence a été dédiée à l'usage des données
d’apprentissage pour les IA génératives et les problèmes qu'elles posent en
matière de droit d'auteur et de propriété intellectuelle. Les IA génératives,
qui produisent du contenu, peuvent menacer la rémunération et la créativité des
auteurs, notamment si elles sont alimentées avec des œuvres protégées par le
droit d'auteur. Charles Bernard a comparé les législations américaine et
européenne : aux États-Unis, le "fair use" permet certaines utilisations,
tandis que la directive européenne 2019/790 sur le "Text and Data Mining"
accorde une exemption aux recherches scientifiques. Cependant, cette exception
reste soumise au droit de réserve des auteurs, posant un défi complexe pour les
législateurs et les praticiens.

Le sujet de la responsabilité civile a également été abordé en profondeur. En
cas d’accident impliquant un système d’IA dans les transports, la question de la
responsabilité est cruciale : qui, du fabricant, du programmeur ou du
propriétaire de l’IA, doit être tenu pour responsable ? La distinction entre
systèmes autonomes et semi-autonomes soulève des problématiques spécifiques,
comme le fait que l'IA puisse évoluer de manière autonome, rendant difficile
l'identification de la source exacte du problème.

Les enjeux en matière de brevets ont aussi été brièvement mentionnés. Alors que
l’IA peut contribuer à la création d’inventions, sa capacité à être elle-même
reconnue comme inventrice ou détentrice de brevets reste floue. De même, la
protection des algorithmes par le droit d'auteur est limitée, sauf en cas
d'effet technique spécifique, ce qui souligne la complexité de la législation
face à l'innovation rapide.

En conclusion, le séminaire a révélé un paysage juridique en pleine mutation,
confronté aux défis croissants posés par l’IA. Charles Bernard a montré que,
bien que l'IA ouvre des perspectives fascinantes, elle soulève également des
questions éthiques et légales cruciales. La réglementation européenne en cours
marque un premier pas vers un encadrement de ces technologies, mais il reste
encore de nombreux défis à relever pour garantir que les avancées technologiques
ne compromettent ni les droits fondamentaux ni la sécurité des individus.

// ---

// Seminaire presente par Charles Bernard (de janson.be) lors de la conference "L'intelligence Artificielle et le droit". Les rapports entre l'IA et le droit. Il a aborde les implications juridiques de l'intelligence artificielle, notamment en matiere de responsabilite, de protection des donnees et de respect de la vie privee. Il a souligne que l'IA pose des defis majeurs pour le droit, qui doit s'adapter a la complexite des systemes autonomes et a la rapidite de leur evolution.

// 1. Introduction
//   - Le premier soucis du juriste, la representabilite.

//   - Resolution du parlement europeen du 16 fevrier 2017 sur les regles de droit civil sur la robotique (2015/2013(INL))

//   - Comment legiferer les lois d'asimov?

//   - L'IA, du fantasme a la realite, les applications innombrables des systemes d'IA. Et donc, il y a de nombreuses question juridiques tres concretes Notamment les problemes ethiques.

// - Par exemple, la police predictive (minority report), la justice predictive. Aujourd'hui c'est devenu une realite: Le Crime Anticipation System.

// - Les biais de l'IA peuvent surgir malheureusement. Une etude a demontre qu'il y avait des biais dans les systemes de justice predictive.

// - Dans l'algorithme COMPAS, pour la detection des recidives, il y avait des biais raciaux.

// - Le chatbot de Microsoft Tay a commence a developper des biais antisemites et racistes en quelques heures seulement. Microsoft a du mettre hors ligne ce chatbot 24h apres sa mise en ligne.

// - IA dans l'administration publique, comme dans la detection de fraude (contre exemple: scandale des alloc familliales au pays bas en 2021)

// - La reconnaissance faciale, atteinte fondamentale a la vie privee. (contre exemple: Clearview AI, pour BDD de reconnaissance faciale illegale).

// - Au dela de ces problemes, il y a aussi des problemes avec les donnees d'apprentissage, quelles sont les donnees qui peuvent etre utilisees? Les IA generatives posent aussi des problemes, notamment car elles peuvent etre utilisees pour creer des deepfakes. Est-ce que cela va influencer la remunerations des auteurs et d'influencer la creativite?

// - Les IA interviennent aussi dans les transports (Amazone Prime Air, UPS), en cas d'accidents, qui est responsable? Le proprietaire du drone, le programmeur, le fabricant?

// - En tant que juriste, de nombreux metier du droits sont menaces. Les avocats, les juges. Les LLMs ne sont pas specialement ideals.

// 3 regles:
//  - Regles relatives aux usages autorises de l'ia (reglemenent UE 2024/1689, EU AI Act)
//    - Entre en vigueur le 2 aout 2026
//    - L'UE a adopte un reglement sur l'ia en 2024, qui vise a encadrer l'utilisation de ces systemes dans l'union europeenne, imposant des exigences de transparence, de responsabilite et de robustesse, de maniere large et global.
//    - S'applique aussi aux entreprises non europeennes, le champs d'application est tres large.
//    - Les obligations s'appliquent aussi bien sur les fournisseurs que sur les
//      deployeurs de systemes d'IA.
//    - Il y a des exceptions pour certaines finalites (militaire, recherche, etc.)
//    - Tout d'abord une definition des systemes d'IA. Une proposition initiale prevoyait une definition renvoyant a des techniques specifiques. Le probleme est le risque d'obsolescence. Et donc, pour corriger ca, on va faire reference a des criteres et technologiquement neutre (system, autonomie, adaptable, objectifs determines, sorties generees a partir de donnees d'entrees, pouvant influencer les environnements physiques ou virtuels).
//    - Classement des systemes d'IA en fonction des risques:
//     - Risques inacceptables
//       - Clearview AI
//       - COMPAS
//       - Inferer les emotions d'une personne physique sur le lieu de travail et ds les etablissements d'enseignement.
//       - Systeme de categorisation biometrique des personnes en fonction de leur origine ethnique ou de leur orientation sexuelle.
//     - Haut risque
//       - Soumis a des obligations strictes
//       - Processus democratique
//       - Migration, Asile
//       - Education et formation
//       - Repression
//       - Quels sont les exigences:
//         - Evaluation Ex Ante
//         - Systeme de gestion des risques (art 9)
//         - Qualite des donnees et de leur traitement (art 10)
//         - Documentation technique (art 11)
//         - Enregistrement des evenements (art 12)
//         - Transparence et obligation d'information (art 13)
//         - Controle humain (art 14)
//         - Precision, robustesse, cybersécurité (art 15)
//     - Risque en matiere de transparence
//     - Risque minimal
//     - Mesures de soutien a l'innovation:
//       - Creation de sandbox reglementaires dans les conditions proches du reel.
//  - Regles relatives a l'utilisation des donnees d'entrainement et de fonctionnement ainsi qu'aux contenus generes par ia
//   - propriete intellectuelle
//   - donnees a caractere personnel (RGPD)
//   - donnees couvertes par la protection des secrets d'affaires
//   - restrictions contractuelles
//   - partage de donnees (Data Act)
// - La responsabilite civile des fournisseurs et utilisateurs de systemes d'IA

// Les IA generatives et les droits d'auteurs:
//  - En amont a l'apprentissage sur les training data des IA generatives
//  - En aval, les contenus generes par les IA generatives

// - Le fait d'alimenter une IA generative avec des oeuvres protegees par le droit d'auteur peut-il constituer une violation de ce droit?
//  - USA: fair use
//  - Europe: Le droit de reproduction dans la CJUE.
//  - La directive 2019/790 - Les exceptions dites "TDM" (text and data mining) permettent des operations specifiques sur des oeuvres protegees par le droit d'auteur pour des finalites de recherche scientifique. Est-ce applicable a l'apprentissage des IA generatives? Selon la CE, oui. Par exemple a des fins de recherche scientifique.
// - Pas de limitation quant au beneficiaire ou a la finalite.
// - Mais... exception generale de TDM est soumise a reserve des titulaires de droits (art 4.3). C'est un opt-out. L'auteur doit exprimer sa reserve.
// - Cela pose des problemes (nightshade) et la technique vient en aide au droit.

// Contenu protegeable par IA?
// - 1ere hypothese: l'oeuvre est le resultat d'une collaboration entre l'homme et la machine.
//   - L'affaire theatre d'opera spatial
// - 2eme hypothese: l'oeuvre est le resultat exclusif de l'IA.
//   - L'affaire de la photo du singe (selfie de Naruto)
// - Les contenus generes par IA sont ils contrefaisants?

// IA et brevet

// - l'IA peut etre inventeur?
// - L'IA peut-elle etre titulaire de brevets?
// - Les algos ne sont pas protegeables par le droit d'auteur, sauf s'il a un effet
// technique specifique (pouvoir l'identifier).

// En cas d'accident autonome, qui est responsable en cas d'accident?
//  - 2 categories:
//   - Les systemes autonomes
//   - Les systemes semi-autonomes
// - Est-ce le fabricant de l'IA ?
//   - peut etre une entreprise non solvable
//   - difficile d'identifier si le probleme vient de l'ia ou de l'interface avec le vehicule
//   - l'ia evolue d'elle meme
//   -
