= Séminaire 4

== L'intelligence artificielle et le droit

Le séminaire "L'intelligence artificielle et le droit" a été présenté par Charles Bernard du cabinet Janson.

Au début, les juristes ne connaissaient pas l'IA. Les juristes ont donc, dans un premier temps, utilisé la SF pour savoir comment légiférer.

Un exemple : les lois formulées en 1942 par les écrivains de science-fiction Isaac Asimov et John W. Campbell. Ces lois sont :

- Un robot ne peut porter atteinte à un être humain ni, restant passif, laisser cet être humain exposé au danger ;
- Un robot doit obéir aux ordres donnés par les êtres humains, sauf si de tels ordres entrent en contradiction avec la première loi ;
- Un robot doit protéger son existence dans la mesure où cette protection n'entre pas en contradiction avec la première ou la deuxième loi.

Mais cette période est révolue : maintenant, l'IA est utilisée dans beaucoup de domaines de la société, ce qui induit donc des questions très concrètes.

Une question très importante est la question de l'éthique ; la police prédictive (qui a d'ailleurs été abordée dans Minority Report) en est un très bon exemple. Pour ce sujet, comment savoir à quel point l'utilisation du système se justifie par son utilisation : le fait de placer plus de policiers dans les zones à risques augmentera indéniablement le nombre d'infractions constatées dans ces zones et donc en validera son utilité. Mais quelle partie de cette augmentation est induite par la présence des policiers ? Sans savoir calculer en détail ces proportions, on ne peut dire si le système marche ou non.

Aux Pays-Bas, la police prédictive a été développée dans le programme "Crime Anticipation System". Grâce à des chercheurs indépendants, il a été démontré que le programme comportait un biais et que les minorités étaient surreprésentées.

Aux USA, le programme COMPAS est un algorithme utilisé par le département de la justice en prédisant le risque de récidive d'un prisonnier. Il a aussi été démontré que l'outil comportait un biais, surévaluant la récidive pour les personnes de couleur noire.

Le problème du biais est un point crucial de l'IA et est très présent. En effet, l'IA est construite par nous, humains, qui avons des biais. De plus, l'IA est entraînée sur des données et, si on ne fait pas attention, ces données vont contenir les biais qui existent dans notre société. L'IA reproduit donc la société humaine qui comporte beaucoup de biais.

Pour ces problèmes de biais, on peut parler par exemple de :

- du chatbot de Microsoft, Tay, qui, apprenant de ses échanges avec les utilisateurs, est devenu raciste en 24h ;
- du scandale en 2021 aux Pays-Bas à propos d'un système devant permettre de détecter la fraude aux allocations familiales qui se basait sur un profilage racial.

Une autre question éthique est l'utilisation de la reconnaissance faciale et de sa compatibilité avec la RGPD.

Mais il n'y a pas que des questions éthiques qui se posent. Des questions liées à la propriété intellectuelle se posent aussi :

- les images générées par de l'IA prédictive sont-elles protégées par le droit d'auteur ?
- est-ce que les IA qui se nourrissent de multiples données respectent bien le droit d'auteur ?

Dans ce domaine, le paradigme a changé : avant, il fallait demander le droit pour utiliser une donnée protégée ; maintenant, c'est aux ayants droit de signaler qu'ils ne veulent pas que leurs données soient utilisées par l'IA. Mais cela ouvre d'autres questions comme de quelle manière l'auteur peut-il signaler qu'il ne veut pas que son œuvre soit utilisée ? Et aussi, comment prouver ou vérifier que c'est bien le cas ?

Dans le domaine de la responsabilité civile, l'arrivée de l'IA apporte aussi des questions hyper intéressantes. Par exemple, qui est responsable en cas d'accident de voiture autonome ? Est-ce le propriétaire de la voiture, le constructeur, le programmeur, le passager ? Une autre question intéressante est de savoir qui est responsable en cas d'incident pour les véhicules autonomes ?

Bref, l'arrivée de l'IA apporte beaucoup de nouvelles questions car elle perturbe pas mal notre société. Le droit doit donc s'y intéresser et proposer des solutions afin d'encadrer l'utilisation de l'IA dans la société. Cet encadrement est très important car il permet est la base du contrat de confiance qu'une société doit avoir avec ses citoyens.

J'ai apprécié l'intervention de Charles Bernard car elle m'a fait découvrir la relation entre l'IA et le droit. Je n'avais pas imaginé que cela posait autant de questions. C'est un sujet assez passionnant. Comme dans beaucoup d'autres domaines, l'arrivée de l'IA est très rapide, elle apporte beaucoup de questions et demande à un secteur de concevoir des solutions très rapidement.